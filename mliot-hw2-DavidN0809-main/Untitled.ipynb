{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d366a045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/david/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "2.11.0\n",
      "/device:GPU:0\n",
      "Training Images range from 0.00000 to 1.00000\n",
      "Test     Images range from 0.00000 to 1.00000\n",
      "Switching to model 1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 1, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 704,842\n",
      "Trainable params: 703,114\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "Model 1 training\n",
      "Epoch 1/50\n",
      "1407/1407 [==============================] - 13s 6ms/step - loss: 1.4925 - accuracy: 0.4627 - val_loss: 1.3677 - val_accuracy: 0.5142\n",
      "Epoch 2/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0908 - accuracy: 0.6114 - val_loss: 1.5305 - val_accuracy: 0.4926\n",
      "Epoch 3/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9030 - accuracy: 0.6842 - val_loss: 0.9070 - val_accuracy: 0.6804\n",
      "Epoch 4/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7573 - accuracy: 0.7360 - val_loss: 0.8363 - val_accuracy: 0.7096\n",
      "Epoch 5/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6318 - accuracy: 0.7791 - val_loss: 0.8171 - val_accuracy: 0.7200\n",
      "Epoch 6/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.5198 - accuracy: 0.8160 - val_loss: 0.8825 - val_accuracy: 0.7144\n",
      "Epoch 7/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.4293 - accuracy: 0.8479 - val_loss: 0.8717 - val_accuracy: 0.7242\n",
      "Epoch 8/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3371 - accuracy: 0.8828 - val_loss: 0.9937 - val_accuracy: 0.7100\n",
      "Epoch 9/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2844 - accuracy: 0.9007 - val_loss: 0.9411 - val_accuracy: 0.7274\n",
      "Epoch 10/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.2346 - accuracy: 0.9186 - val_loss: 1.0387 - val_accuracy: 0.7170\n",
      "Epoch 11/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1969 - accuracy: 0.9313 - val_loss: 1.0603 - val_accuracy: 0.7294\n",
      "Epoch 12/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1777 - accuracy: 0.9382 - val_loss: 1.1313 - val_accuracy: 0.7172\n",
      "Epoch 13/50\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 1.1564 - val_accuracy: 0.7364\n",
      "Epoch 14/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1400 - accuracy: 0.9517 - val_loss: 1.2496 - val_accuracy: 0.7162\n",
      "Epoch 15/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1292 - accuracy: 0.9558 - val_loss: 1.1778 - val_accuracy: 0.7270\n",
      "Epoch 16/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1175 - accuracy: 0.9592 - val_loss: 1.2012 - val_accuracy: 0.7314\n",
      "Epoch 17/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1108 - accuracy: 0.9622 - val_loss: 1.3227 - val_accuracy: 0.7098\n",
      "Epoch 18/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1076 - accuracy: 0.9628 - val_loss: 1.3403 - val_accuracy: 0.7180\n",
      "Epoch 19/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0958 - accuracy: 0.9666 - val_loss: 1.3105 - val_accuracy: 0.7364\n",
      "Epoch 20/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0902 - accuracy: 0.9691 - val_loss: 1.3720 - val_accuracy: 0.7224\n",
      "Epoch 21/50\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.0923 - accuracy: 0.9680 - val_loss: 1.3457 - val_accuracy: 0.7300\n",
      "Epoch 22/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0813 - accuracy: 0.9716 - val_loss: 1.4028 - val_accuracy: 0.7194\n",
      "Epoch 23/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0823 - accuracy: 0.9720 - val_loss: 1.3624 - val_accuracy: 0.7214\n",
      "Epoch 24/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0745 - accuracy: 0.9748 - val_loss: 1.3387 - val_accuracy: 0.7432\n",
      "Epoch 25/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0700 - accuracy: 0.9762 - val_loss: 1.4020 - val_accuracy: 0.7304\n",
      "Epoch 26/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0737 - accuracy: 0.9747 - val_loss: 1.5522 - val_accuracy: 0.7174\n",
      "Epoch 27/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0678 - accuracy: 0.9770 - val_loss: 1.4746 - val_accuracy: 0.7252\n",
      "Epoch 28/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0668 - accuracy: 0.9775 - val_loss: 1.4189 - val_accuracy: 0.7362\n",
      "Epoch 29/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0592 - accuracy: 0.9789 - val_loss: 1.5459 - val_accuracy: 0.7240\n",
      "Epoch 30/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0614 - accuracy: 0.9791 - val_loss: 1.4838 - val_accuracy: 0.7294\n",
      "Epoch 31/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 1.4588 - val_accuracy: 0.7268\n",
      "Epoch 32/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0588 - accuracy: 0.9802 - val_loss: 1.4042 - val_accuracy: 0.7376\n",
      "Epoch 33/50\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 1.5158 - val_accuracy: 0.7292\n",
      "Epoch 34/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 1.4329 - val_accuracy: 0.7414\n",
      "Epoch 35/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0483 - accuracy: 0.9833 - val_loss: 1.5614 - val_accuracy: 0.7240\n",
      "Epoch 36/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 1.6153 - val_accuracy: 0.7230\n",
      "Epoch 37/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0510 - accuracy: 0.9830 - val_loss: 1.5284 - val_accuracy: 0.7356\n",
      "Epoch 38/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0473 - accuracy: 0.9846 - val_loss: 1.5560 - val_accuracy: 0.7308\n",
      "Epoch 39/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0408 - accuracy: 0.9859 - val_loss: 1.6141 - val_accuracy: 0.7310\n",
      "Epoch 40/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0488 - accuracy: 0.9840 - val_loss: 1.5318 - val_accuracy: 0.7362\n",
      "Epoch 41/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0434 - accuracy: 0.9853 - val_loss: 1.5608 - val_accuracy: 0.7258\n",
      "Epoch 42/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0426 - accuracy: 0.9857 - val_loss: 1.4579 - val_accuracy: 0.7326\n",
      "Epoch 43/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 1.5361 - val_accuracy: 0.7390\n",
      "Epoch 44/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 1.5984 - val_accuracy: 0.7304\n",
      "Epoch 45/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 1.5712 - val_accuracy: 0.7390\n",
      "Epoch 46/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0379 - accuracy: 0.9875 - val_loss: 1.5722 - val_accuracy: 0.7310\n",
      "Epoch 47/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 1.5717 - val_accuracy: 0.7396\n",
      "Epoch 48/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 1.5765 - val_accuracy: 0.7324\n",
      "Epoch 49/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 1.5609 - val_accuracy: 0.7418\n",
      "Epoch 50/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 1.5654 - val_accuracy: 0.7332\n",
      "Switching to model 2\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 8, 8, 64)         2400      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 4, 4, 128)        8896      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 4, 4, 128)        17664     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 4, 4, 128)        17664     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 4, 4, 128)        17664     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_5 (Separab  (None, 4, 4, 128)        17664     \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 1, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,594\n",
      "Trainable params: 102,122\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "Model 2 training\n",
      "Epoch 1/50\n",
      "1407/1407 [==============================] - 10s 5ms/step - loss: 1.6486 - accuracy: 0.3966 - val_loss: 1.4477 - val_accuracy: 0.4780\n",
      "Epoch 2/50\n",
      "1407/1407 [==============================] - 6s 5ms/step - loss: 1.3413 - accuracy: 0.5149 - val_loss: 1.3958 - val_accuracy: 0.4934\n",
      "Epoch 3/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1845 - accuracy: 0.5763 - val_loss: 1.1750 - val_accuracy: 0.5784\n",
      "Epoch 4/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0709 - accuracy: 0.6199 - val_loss: 1.0811 - val_accuracy: 0.6136\n",
      "Epoch 5/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9908 - accuracy: 0.6499 - val_loss: 1.0530 - val_accuracy: 0.6308\n",
      "Epoch 6/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.9197 - accuracy: 0.6755 - val_loss: 1.0304 - val_accuracy: 0.6440\n",
      "Epoch 7/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8643 - accuracy: 0.6939 - val_loss: 1.0441 - val_accuracy: 0.6356\n",
      "Epoch 8/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8127 - accuracy: 0.7127 - val_loss: 1.0798 - val_accuracy: 0.6348\n",
      "Epoch 9/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.7688 - accuracy: 0.7278 - val_loss: 0.9777 - val_accuracy: 0.6634\n",
      "Epoch 10/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7217 - accuracy: 0.7441 - val_loss: 0.9552 - val_accuracy: 0.6742\n",
      "Epoch 11/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6835 - accuracy: 0.7558 - val_loss: 1.0331 - val_accuracy: 0.6598\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6487 - accuracy: 0.7692 - val_loss: 0.9942 - val_accuracy: 0.6628\n",
      "Epoch 13/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6180 - accuracy: 0.7784 - val_loss: 0.9895 - val_accuracy: 0.6648\n",
      "Epoch 14/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.5884 - accuracy: 0.7913 - val_loss: 1.0292 - val_accuracy: 0.6706\n",
      "Epoch 15/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.5614 - accuracy: 0.7994 - val_loss: 1.0269 - val_accuracy: 0.6794\n",
      "Epoch 16/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.5352 - accuracy: 0.8100 - val_loss: 1.0131 - val_accuracy: 0.6786\n",
      "Epoch 17/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.5089 - accuracy: 0.8188 - val_loss: 1.0456 - val_accuracy: 0.6644\n",
      "Epoch 18/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4898 - accuracy: 0.8253 - val_loss: 1.0709 - val_accuracy: 0.6758\n",
      "Epoch 19/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4721 - accuracy: 0.8320 - val_loss: 1.0775 - val_accuracy: 0.6704\n",
      "Epoch 20/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4492 - accuracy: 0.8394 - val_loss: 1.0700 - val_accuracy: 0.6814\n",
      "Epoch 21/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4305 - accuracy: 0.8453 - val_loss: 1.1496 - val_accuracy: 0.6656\n",
      "Epoch 22/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.4138 - accuracy: 0.8529 - val_loss: 1.0914 - val_accuracy: 0.6774\n",
      "Epoch 23/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3986 - accuracy: 0.8571 - val_loss: 1.1518 - val_accuracy: 0.6688\n",
      "Epoch 24/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3801 - accuracy: 0.8648 - val_loss: 1.1742 - val_accuracy: 0.6634\n",
      "Epoch 25/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3658 - accuracy: 0.8691 - val_loss: 1.1483 - val_accuracy: 0.6722\n",
      "Epoch 26/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3539 - accuracy: 0.8735 - val_loss: 1.1659 - val_accuracy: 0.6712\n",
      "Epoch 27/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3472 - accuracy: 0.8752 - val_loss: 1.2121 - val_accuracy: 0.6672\n",
      "Epoch 28/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3312 - accuracy: 0.8824 - val_loss: 1.2098 - val_accuracy: 0.6680\n",
      "Epoch 29/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3213 - accuracy: 0.8861 - val_loss: 1.2091 - val_accuracy: 0.6788\n",
      "Epoch 30/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3161 - accuracy: 0.8863 - val_loss: 1.2612 - val_accuracy: 0.6690\n",
      "Epoch 31/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.3005 - accuracy: 0.8933 - val_loss: 1.3136 - val_accuracy: 0.6704\n",
      "Epoch 32/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.2897 - accuracy: 0.8964 - val_loss: 1.3141 - val_accuracy: 0.6666\n",
      "Epoch 33/50\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.2822 - accuracy: 0.8983 - val_loss: 1.3004 - val_accuracy: 0.6734\n",
      "Epoch 34/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2780 - accuracy: 0.9007 - val_loss: 1.3802 - val_accuracy: 0.6714\n",
      "Epoch 35/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2631 - accuracy: 0.9060 - val_loss: 1.4130 - val_accuracy: 0.6588\n",
      "Epoch 36/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2598 - accuracy: 0.9065 - val_loss: 1.4439 - val_accuracy: 0.6544\n",
      "Epoch 37/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2607 - accuracy: 0.9062 - val_loss: 1.4582 - val_accuracy: 0.6538\n",
      "Epoch 38/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2507 - accuracy: 0.9100 - val_loss: 1.3601 - val_accuracy: 0.6738\n",
      "Epoch 39/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2397 - accuracy: 0.9149 - val_loss: 1.4465 - val_accuracy: 0.6618\n",
      "Epoch 40/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2417 - accuracy: 0.9139 - val_loss: 1.3890 - val_accuracy: 0.6706\n",
      "Epoch 41/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2344 - accuracy: 0.9168 - val_loss: 1.4038 - val_accuracy: 0.6758\n",
      "Epoch 42/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2321 - accuracy: 0.9162 - val_loss: 1.3840 - val_accuracy: 0.6730\n",
      "Epoch 43/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2252 - accuracy: 0.9194 - val_loss: 1.4099 - val_accuracy: 0.6794\n",
      "Epoch 44/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2207 - accuracy: 0.9207 - val_loss: 1.4258 - val_accuracy: 0.6664\n",
      "Epoch 45/50\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2142 - accuracy: 0.9232 - val_loss: 1.4524 - val_accuracy: 0.6624\n",
      "Epoch 46/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2074 - accuracy: 0.9258 - val_loss: 1.4813 - val_accuracy: 0.6722\n",
      "Epoch 47/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2066 - accuracy: 0.9256 - val_loss: 1.5122 - val_accuracy: 0.6638\n",
      "Epoch 48/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.2038 - accuracy: 0.9269 - val_loss: 1.4702 - val_accuracy: 0.6668\n",
      "Epoch 49/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1992 - accuracy: 0.9280 - val_loss: 1.4546 - val_accuracy: 0.6728\n",
      "Epoch 50/50\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1899 - accuracy: 0.9311 - val_loss: 1.5213 - val_accuracy: 0.6708\n",
      "Switching to model 3\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 32)   896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 16, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 16, 16, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 64)     18496       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 8, 8, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 64)     36928       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 8, 8, 64)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 8, 8, 64)     0           ['dropout_2[0][0]',              \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 4, 4, 128)    73856       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 4, 128)    8320        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 4, 128)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4, 4, 128)    0           ['dropout_3[0][0]',              \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 4, 4, 128)    147584      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 4, 4, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 4, 128)    147584      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 4, 128)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 4, 4, 128)    147584      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 4, 4, 128)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 128)    147584      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 4, 4, 128)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 4, 4, 128)    0           ['dropout_7[0][0]',              \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1, 1, 128)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          16512       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           1290        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 750,346\n",
      "Trainable params: 748,490\n",
      "Non-trainable params: 1,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 training\n",
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 14s 6ms/step - loss: 1.7700 - accuracy: 0.3558 - val_loss: 3.7136 - val_accuracy: 0.0978\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4252 - accuracy: 0.4871 - val_loss: 3.1274 - val_accuracy: 0.1006\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2726 - accuracy: 0.5498 - val_loss: 4.1137 - val_accuracy: 0.0978\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1536 - accuracy: 0.5939 - val_loss: 3.7286 - val_accuracy: 0.0996\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0581 - accuracy: 0.6297 - val_loss: 2.9745 - val_accuracy: 0.0996\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9789 - accuracy: 0.6612 - val_loss: 3.5480 - val_accuracy: 0.0996\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9154 - accuracy: 0.6857 - val_loss: 3.9043 - val_accuracy: 0.0998\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8632 - accuracy: 0.7041 - val_loss: 3.5760 - val_accuracy: 0.0994\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8242 - accuracy: 0.7171 - val_loss: 3.7894 - val_accuracy: 0.0996\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7849 - accuracy: 0.7309 - val_loss: 4.2405 - val_accuracy: 0.0996\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7532 - accuracy: 0.7401 - val_loss: 4.2346 - val_accuracy: 0.0996\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7252 - accuracy: 0.7500 - val_loss: 4.1805 - val_accuracy: 0.0996\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7045 - accuracy: 0.7588 - val_loss: 4.7587 - val_accuracy: 0.1000\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6769 - accuracy: 0.7687 - val_loss: 4.9855 - val_accuracy: 0.0996\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6538 - accuracy: 0.7765 - val_loss: 3.5764 - val_accuracy: 0.0980\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6381 - accuracy: 0.7822 - val_loss: 4.3395 - val_accuracy: 0.0992\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6188 - accuracy: 0.7875 - val_loss: 4.8399 - val_accuracy: 0.0998\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6060 - accuracy: 0.7935 - val_loss: 6.1356 - val_accuracy: 0.0996\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5921 - accuracy: 0.7980 - val_loss: 5.5121 - val_accuracy: 0.1002\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5767 - accuracy: 0.8018 - val_loss: 5.6535 - val_accuracy: 0.0996\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5651 - accuracy: 0.8063 - val_loss: 5.5472 - val_accuracy: 0.0992\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5522 - accuracy: 0.8098 - val_loss: 8.5944 - val_accuracy: 0.0996\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5489 - accuracy: 0.8123 - val_loss: 6.3796 - val_accuracy: 0.1002\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5315 - accuracy: 0.8182 - val_loss: 7.2294 - val_accuracy: 0.1000\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5226 - accuracy: 0.8194 - val_loss: 6.5861 - val_accuracy: 0.0990\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5126 - accuracy: 0.8233 - val_loss: 8.3205 - val_accuracy: 0.1000\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5035 - accuracy: 0.8275 - val_loss: 7.4679 - val_accuracy: 0.0936\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4948 - accuracy: 0.8295 - val_loss: 7.3145 - val_accuracy: 0.0992\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4853 - accuracy: 0.8315 - val_loss: 10.1477 - val_accuracy: 0.0996\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4797 - accuracy: 0.8351 - val_loss: 8.6680 - val_accuracy: 0.0994\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4720 - accuracy: 0.8367 - val_loss: 7.7049 - val_accuracy: 0.0994\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4623 - accuracy: 0.8379 - val_loss: 8.6980 - val_accuracy: 0.0996\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4569 - accuracy: 0.8417 - val_loss: 9.9850 - val_accuracy: 0.0998\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4518 - accuracy: 0.8441 - val_loss: 10.4626 - val_accuracy: 0.0994\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4443 - accuracy: 0.8461 - val_loss: 10.0127 - val_accuracy: 0.0938\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4374 - accuracy: 0.8490 - val_loss: 10.4173 - val_accuracy: 0.0938\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4297 - accuracy: 0.8508 - val_loss: 10.9641 - val_accuracy: 0.1100\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4207 - accuracy: 0.8545 - val_loss: 11.5632 - val_accuracy: 0.0952\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4270 - accuracy: 0.8517 - val_loss: 11.0549 - val_accuracy: 0.0996\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4184 - accuracy: 0.8564 - val_loss: 9.7497 - val_accuracy: 0.0996\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4135 - accuracy: 0.8575 - val_loss: 10.1014 - val_accuracy: 0.1028\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4044 - accuracy: 0.8615 - val_loss: 10.7670 - val_accuracy: 0.0996\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3979 - accuracy: 0.8629 - val_loss: 10.2581 - val_accuracy: 0.0970\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3950 - accuracy: 0.8644 - val_loss: 11.7026 - val_accuracy: 0.0996\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3931 - accuracy: 0.8647 - val_loss: 10.1195 - val_accuracy: 0.0982\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3887 - accuracy: 0.8668 - val_loss: 12.4019 - val_accuracy: 0.0934\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3860 - accuracy: 0.8669 - val_loss: 11.0039 - val_accuracy: 0.0964\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3848 - accuracy: 0.8678 - val_loss: 13.0645 - val_accuracy: 0.0988\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3780 - accuracy: 0.8708 - val_loss: 13.8539 - val_accuracy: 0.0996\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3718 - accuracy: 0.8707 - val_loss: 14.9184 - val_accuracy: 0.0996\n",
      "Switching to model 50k\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 8, 8, 64)         2400      \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_5 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_6 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_7 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " separable_conv2d_8 (Separab  (None, 4, 4, 64)         4736      \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 4, 4, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 1, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,682\n",
      "Trainable params: 47,338\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n",
      "Training model50k with early stop of patience <keras.callbacks.EarlyStopping object at 0x7fa133a83700>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 13s 6ms/step - loss: 1.8097 - accuracy: 0.3310 - val_loss: 2.9171 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4422 - accuracy: 0.4752 - val_loss: 2.7335 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2889 - accuracy: 0.5392 - val_loss: 3.1690 - val_accuracy: 0.1000\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1824 - accuracy: 0.5736 - val_loss: 3.3772 - val_accuracy: 0.0992\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1027 - accuracy: 0.6074 - val_loss: 2.9892 - val_accuracy: 0.0986\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0383 - accuracy: 0.6321 - val_loss: 3.4276 - val_accuracy: 0.0996\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9716 - accuracy: 0.6546 - val_loss: 4.3275 - val_accuracy: 0.0978\n"
     ]
    }
   ],
   "source": [
    "!python3 hw2_complete.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de586310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/david/anaconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.2.1, pluggy-1.0.0\n",
      "rootdir: /home/david/Documents/GitHub/mliot-hw2-DavidN0809\n",
      "plugins: hydra-core-1.3.1, anyio-3.6.2\n",
      "\u001b[1mcollecting ... \u001b[0mFatal Python error: Aborted\n",
      "\n",
      "Current thread 0x00007fd578f311c0 (most recent call first):\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/tensorflow/python/client/device_lib.py\", line 41 in list_local_devices\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/tensorflow/python/framework/test_util.py\", line 165 in gpu_device_name\n",
      "  File \"/home/david/Documents/GitHub/mliot-hw2-DavidN0809/hw2_complete.py\", line 21 in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 241 in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883 in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 688 in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006 in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027 in _find_and_load\n",
      "  File \"/home/david/Documents/GitHub/mliot-hw2-DavidN0809/hw2_test.py\", line 15 in <module>\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/assertion/rewrite.py\", line 168 in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 688 in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006 in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027 in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050 in _gcd_import\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126 in import_module\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/pathlib.py\", line 533 in import_path\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/python.py\", line 618 in _importtestmodule\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/python.py\", line 529 in _getobj\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/python.py\", line 311 in obj\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/python.py\", line 546 in _inject_setup_module_fixture\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/python.py\", line 532 in collect\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/runner.py\", line 370 in <lambda>\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/runner.py\", line 339 in from_call\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/runner.py\", line 370 in pytest_make_collect_report\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 39 in _multicall\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_manager.py\", line 80 in _hookexec\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_hooks.py\", line 265 in __call__\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/runner.py\", line 538 in collect_one_node\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/main.py\", line 831 in genitems\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/main.py\", line 664 in perform_collect\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/main.py\", line 334 in pytest_collection\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 39 in _multicall\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_manager.py\", line 80 in _hookexec\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_hooks.py\", line 265 in __call__\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/main.py\", line 323 in _main\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/main.py\", line 270 in wrap_session\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/main.py\", line 317 in pytest_cmdline_main\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_callers.py\", line 39 in _multicall\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_manager.py\", line 80 in _hookexec\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pluggy/_hooks.py\", line 265 in __call__\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 167 in main\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 190 in console_main\n",
      "  File \"/home/david/.local/bin/pytest\", line 8 in <module>\n",
      "\n",
      "Extension modules: yaml._yaml, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg.lapack_lite, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, google.protobuf.pyext._message, tensorflow.python.framework.fast_tensor_util, _cffi_backend, h5py._errors, h5py.defs, h5py._objects, h5py.h5, h5py.h5r, h5py.utils, h5py.h5s, h5py.h5ac, h5py.h5p, h5py.h5t, h5py._conv, h5py.h5z, h5py._proxy, h5py.h5a, h5py.h5d, h5py.h5ds, h5py.h5g, h5py.h5i, h5py.h5f, h5py.h5fd, h5py.h5pl, h5py.h5o, h5py.h5l, h5py._selector, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._isolve._iterative, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg._cythonized_array_utils, scipy.linalg._flinalg, scipy.linalg._solve_toeplitz, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_lapack, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, PIL._imaging, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.tslib, pandas._libs.lib, pandas._libs.hashing, pyarrow.lib, pyarrow._hdfsio, pandas._libs.ops, pyarrow._compute, pandas._libs.arrays, pandas._libs.index, pandas._libs.join, pandas._libs.sparse, pandas._libs.reduction, pandas._libs.indexing, pandas._libs.internals, pandas._libs.writers, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.tslibs.strptime, pandas._libs.groupby, pandas._libs.testing, pandas._libs.parsers, pandas._libs.json, scipy.ndimage._nd_image, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, _ni_label, scipy.ndimage._ni_label, matplotlib._c_internal_utils, matplotlib._path, kiwisolver._cext, matplotlib._image (total: 123)\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a394af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
